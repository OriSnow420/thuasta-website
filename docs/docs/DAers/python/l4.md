# L4-Torch使用

## 1. Torch库是什么？

`torch` 是一个广泛使用的开源机器学习库，它提供了丰富的功能来支持深度学习研究和开发。  

`torch` 提供了灵活的张量操作、自动求导机制以及GPU加速等功能。它使得开发者能够快速构建和训练复杂的神经网络模型。  

## 2. 安装Torch库

### 2.1 Anaconda安装

Anaconda是python的包管理器，可以很方便的管理不同项目的python环境，解决不同项目python包的环境冲突问题。

我们做python项目时要养成良好的习惯，不同的python项目要采取不同的python虚拟环境，不同的虚拟环境之间相互隔离，python版本和包均不共用。python虚拟环境的创建和管理常用Anaconda。

安装Anaconda步骤：  

官网下载安装包：<https://www.anaconda.com/distribution/> ，随后运行并选择安装路径，等待安装完成。(要记得勾选 Add Anaconda to the system PATH environment variable，是为了将Anaconda添加到环境变量中。是的它显示不建议你这样做，但我建议你这样做，要不然还要自己手动把他添加到环境变量里)。

安装完毕，查看是否安装成功。  
在cmd(按住win+R)中输入conda

```bash
C:\Users>conda
```

回车，如果出现如下信息则说明安装成功。

```bash
C:\Users>conda
usage: conda-script.py [-h][-V] command ...
conda is a tool for managing and deploying applications, environments and packages.
Options :
positional arguments :
...
```

### 2.2 CUDA与cuDNN安装

（如果没有GPU跳过此步骤）  
这里建议在CSDN上搜索教程安装。需要检查电脑所支持的CUDA版本，不要安装错版本。

### 2.3 Pytorch安装

#### （1）配置torch环境

打开Anaconda Prompt(anaconda)，然后输入

```bash
conda env list
```  

命令行中会显示出当前已存在的python虚拟环境，如果是刚安装anaconda,应该只有一个base基环境。

下面我们新建立一个python虚拟环境(命名为new)

```bash
conda create -n new python=3.12
```  

这里为了在创建环境的时候指定了python解释器的版本，避免疏漏

然后激活环境。在anaconda prompt中输入：

```bash
conda activate new
```

可以看到命令行中base变成了new，说明成功了。

```bash
(new) C:\Users\李翔宇>
```

此时再进行python包的安装就是对这个虚拟环境操作，比如我们输入

```bash
pip install numpy
```

或者

```bash
conda install numpy
```

再输入

```bash
conda list
```

就可以看到new这个虚拟环境里面已经有numpy这个包了。说明numpy安装成功。

#### （2）pytorch的安装

打开pytorch官网：<https://pytorch.org/get-started/previous-versions/> 找到自己所对应版本的使用conda命令安装即可

至此pytorch应该就安装完成了。下面介绍torch库。

## 3. Torch库简介

### 3.1 张量tensor的创建

张量可以理解成多维数组。  
以下是torch中有关函数和代码示例：  
`torch.tensor` 从数据创建张量

```python
import torch

# 从数据创建
x = torch.tensor([1, 2, 3])          # 标量或列表转张量
x = torch.tensor([[1, 2], [3, 4]])   # 2D张量（矩阵）
```

`torch.arange` 顺序创建张量

```python
# 顺序创建
y = torch.arange(5)              # tensor([0, 1, 2, 3, 4]),默认start=0, step=1
y = torch.arange(1, 4)           # tensor([1, 2, 3]),指定start和end
y = torch.arange(1, 2.5, 0.5)    # tensor([1.0, 1.5, 2.0]),支持浮点数步长
```

`torch.zeros` 全0张量

```python
zeros = torch.zeros(2, 3)            # 全0张量
#tensor([[0, 0, 0], [0, 0, 0]])
```

`torch.ones` 全1张量

```python
ones = torch.ones(2, 3)              # 全1张量
#tensor([[1, 1, 1], [1, 1, 1]])
```

`torch.rand` 均匀随机张量

```python
rand = torch.rand(2, 3)              # 均匀随机张量（0~1）
#tensor([[0.1234, 0.5678, 0.9012], [0.3456, 0.7890, 0.2345]])
```

`torch.randn` 标准正态分布张量

```python
randn = torch.randn(2, 3)            # 标准正态分布张量
#tensor([[ 0.1234, -0.5678,  1.2345], [-0.3456,  0.7890, -1.2345]])
```

`torch.eye` 单位矩阵

```python
eye = torch.eye(3)                   # 单位矩阵
#tensor([[1., 0., 0.],
#        [0., 1., 0.],
#        [0., 0., 1.]])
```

`torch.zeros_like` 形状同另一个张量的全0张量

```python
x_like = torch.zeros_like(rand)      # 形状同rand的全0张量
```

### 3.2 张量tensor的形状操作

`view` 调整形状,要求张量的内存必须是连续的  
`reshape` 调整形状,但不要求输入张量是连续的  
`flatten` 展平为1维张量  
`T` 转置  
`permute` 维度交换  
`unsqueezed` 增加维度  
`squeezed` 压缩维度  

```python
import torch

x = torch.tensor([[1, 2, 3], [4, 5, 6]])

# 调整形状
view = x.view(3, 2)                  # tensor([[1, 2], [3, 4], [5, 6]])
reshaped = x.reshape(3, 2)           # tensor([[1, 2], [3, 4], [5, 6]]) 
flattened = x.flatten()              # tensor([1, 2, 3, 4, 5, 6])

# 转置
transposed = x.T                     # tensor([[1, 4], [2, 5], [3, 6]])
                                     # 等价于 x.transpose(0, 1)

# 维度交换  
permuted = x.permute(1, 0)           # tensor([[1, 4], [2, 5], [3, 6]]) 
                                     # 效果与transpose相同

# 增加/压缩维度
unsqueezed = x.unsqueeze(0)          # tensor([[[1, 2, 3], [4, 5, 6]]]) 
                                     # shape: (1, 2, 3)
squeezed = unsqueezed.squeeze(0)     # tensor([[1, 2, 3], [4, 5, 6]])
                                     # 恢复原shape: (2, 3)
```

### 3.3 数学运算

`+` 加  
`-` 减  
`*` 乘  
`/` 除  
`sqrt` 平方根  
`matmul` 矩阵乘法  
`sum` 求和  
`mean` 均值  
`max` 最大值及索引  

```python
import torch

a = torch.tensor([[1, 2, 3], [4, 5, 6]])
b = torch.tensor([[1, 3, 5], [2, 4, 6]])

# 逐元素运算
add = a + b                          # tensor([[2, 5, 8], [6, 9, 12]])
mul = a * b                          # tensor([[1, 6, 15], [8, 20, 36]])
div = a / b                          # tensor([[1.0000, 0.6667, 0.6000],
                                     #         [2.0000, 1.2500, 1.0000]])
sqrt = torch.sqrt(a)                 # tensor([[1.0000, 1.4142, 1.7321],
                                     #         [2.0000, 2.2361, 2.4495]])

# 正确维度的矩阵乘法示例
mat_a = torch.tensor([[1, 2, 3], 
                     [4, 5, 6]])  
mat_b = torch.tensor([[1, 3], 
                     [5, 2],
                     [4, 6]])        

matmul = torch.matmul(mat_a, mat_b)  # 或 mat_a @ mat_b
                                     #tensor([[23, 25],
                                     #        [53, 58]])

# 归约运算
sum_all = a.sum()                    # tensor(21)（1+2+...+6）
sum_dim = a.sum(dim=0)               # tensor([5, 7, 9])（列求和）
mean = a.mean()                      # tensor(3.5000)（21/6）
max_val, max_idx = a.max(dim=1)      # (tensor([3, 6]), tensor([2, 2]))
                                     # 每行最大值及其索引
```

### 3.4 索引与切片

一般都是使用start : end : step来表示获取的数据范围，范围是前闭后开，step表示步长。Pytorch不支持负步长，但是支持负索引，-1指的是该维度下的最后一个索引。

```python
import torch
x = torch.arange(12).reshape(3, 4)  # 3行4列
print(x)
# tensor([[ 0,  1,  2,  3],
#         [ 4,  5,  6,  7],
#         [ 8,  9, 10, 11]])

# 切片操作
row_slice = x[1, :]      # 第2行所有列 → [4, 5, 6, 7]
col_slice = x[:, 2]      # 所有行第3列 → [2, 6, 10]
block = x[0:2, 1:3]      # 第1-2行，第2-3列 → [[1, 2], [5, 6]]
step_slice = x[::2, ::3] # 隔行(步长2)隔列(步长3) → [[0, 3], [8, 11]]

# 布尔掩码
mask = x > 0.5
selected = x[mask]                   # 返回1D张量
```

### 3.5 类型与设备转换

```python
x = torch.rand(2, 3)
 
# 数据类型转换
x_float = x.float()                  # 转为float32
x_double = x.double()                # 转为float64
 
# 设备转移（CPU/GPU）
if torch.cuda.is_available():
    x_gpu = x.to('cuda')             # 转移到GPU
    x_cpu = x_gpu.to('cpu')          # 转回CPU
```

### 3.6 广播机制

广播的意思是自动扩展维度以匹配操作；广播机制允许不同形状的张量在某些维度自动扩展以实现数学运算。  

核心规则如下：

1. 从后往前比对维度：

2. 两维相等，或其中一维为1，可以扩展

3. 否则报错

示例：

```python
#标量广播
a = torch.tensor([[1, 2], [3, 4]])
b = torch.tensor(10)
a + b     # 等效于 [[11, 12], [13, 14]]

#维度自动扩展
a = torch.tensor([[1], [2], [3]])   # (3,1)
b = torch.tensor([10, 20])          # (2,)
a + b   # 结果为(3,2)，广播为 [[11, 21], [12, 22], [13, 23]]

#批量矩阵加偏置
x = torch.randn(32, 100)            # batch_size = 32
bias = torch.randn(100)             # 对每个样本添加同样的偏置
out = x + bias
```

广播操作无须显式扩展维度，节省内存，是深度学习模型中常见的操作模式

### 3.7 张量拼接与分割

```python
a, b = torch.rand(2, 3), torch.rand(2, 3)
 
# 拼接
cat = torch.cat([a, b], dim=0)       # 沿0维拼接 → (4, 3)
stack = torch.stack([a, b], dim=0)   # 新维堆叠 → (2, 2, 3)
 
# 分割
chunks = torch.chunk(cat, 2, dim=0)  # 将张量沿指定维度 dim=0 均匀分成2块（尽可能均分）
split = torch.split(cat, 2, dim=0)   # 每块大小2
 
# 选择
dim_0_0 = torch.select(cat, 0, 0)    # 沿维度 0 选择索引为 0 的子张量 → (1, 3)
dim_0_1 = torch.select(cat, 0, 1)    # 沿维度 0 选择索引为 1 的子张量 → (1, 3)
```

### 3.8 其他使用操作

```python
x = torch.tensor([1, 2, 3])
 
# 克隆（避免共享内存）
y = x.clone()                        # 独立副本
 
# 原地操作（避免内存分配）
x.add_(1)                            # 等价于 x += 1
 
# 条件赋值
y = torch.where(x > 1, x, torch.zeros_like(x))  # >1保留，否则置0
```

## 总结

PyTorch是一个广泛使用的开源机器学习库，提供灵活的张量操作、自动求导机制和GPU加速功能，支持深度学习研究和开发。

### 核心功能

#### 张量创建

- `torch.tensor()` - 从数据创建张量
- `torch.arange()` - 创建顺序张量
- `torch.zeros()` - 创建全0张量
- `torch.ones()` - 创建全1张量
- `torch.rand()` - 创建均匀随机张量
- `torch.randn()` - 创建正态分布张量
- `torch.eye()` - 创建单位矩阵

#### 形状操作

- `view()` - 调整张量形状（需连续内存）
- `reshape()` - 调整张量形状（无需连续内存）
- `flatten()` - 展平为1维张量
- `T` - 张量转置
- `permute()` - 维度交换
- `unsqueeze()` - 增加维度
- `squeeze()` - 压缩维度

#### 数学运算

- `+`, `-`, `*`, `/` - 基本算术运算
- `torch.sqrt()` - 平方根计算
- `torch.matmul()` - 矩阵乘法
- `sum()` - 求和计算
- `mean()` - 均值计算
- `max()` - 最大值及索引查找

#### 索引切片

- `x[i, j]` - 基本索引
- `x[start:end:step]` - 切片操作
- `x[mask]` - 布尔掩码索引

#### 类型设备转换

- `.float()` - 转换为float32类型
- `.double()` - 转换为float64类型
- `.to('cuda')` - 转移到GPU设备
- `.to('cpu')` - 转移回CPU设备

#### 广播机制

- 自动维度扩展 - 不同形状张量的运算支持
- 标量广播 - 标量与张量的自动运算
- 维度匹配 - 按规则自动扩展维度

#### 张量操作

- `torch.cat()` - 张量拼接
- `torch.stack()` - 张量堆叠
- `torch.chunk()` - 张量分块
- `torch.split()` - 按大小分割
- `torch.select()` - 维度选择

#### 高级操作

- `.clone()` - 张量克隆（避免共享内存）
- `add_()` - 原地操作（节省内存）
- `torch.where()` - 条件赋值操作

#### GPU支持

- `torch.cuda.is_available()` - 检测GPU可用性
- CUDA版本匹配 - 确保GPU驱动兼容
- 设备转移 - CPU/GPU间数据迁移
